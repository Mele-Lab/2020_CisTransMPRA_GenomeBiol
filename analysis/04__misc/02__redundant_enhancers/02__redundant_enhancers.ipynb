{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02__redundant_enhancers\n",
    "\n",
    "in this notebook, i find \"redundant\" enhancers for every element in the MPRA -- i.e. those whose CAGE-seq expression profiles are correlated above a certain threshold with element of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from random import shuffle\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# import utils\n",
    "sys.path.append(\"../../../utils\")\n",
    "from plotting_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "mpl.rcParams['figure.autolayout'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(**PAPER_PRESET)\n",
    "fontsize = PAPER_FONTSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANT_ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_otsu(arr, n_bins, range_min, range_max):\n",
    "    hist, bins = np.histogram(arr, bins=n_bins, range=(range_min, range_max))\n",
    "    bins = bins[:-1]\n",
    "    hist_norm = hist.ravel()/hist.max()\n",
    "    Q = hist_norm.cumsum()\n",
    "    fn_min = np.inf\n",
    "    thresh = -1\n",
    "    for i in range(1, n_bins):\n",
    "        p1, p2 = np.hsplit(hist_norm, [i])\n",
    "        q1, q2 = Q[i], Q[n_bins-1] - Q[i]\n",
    "        b1, b2 = np.hsplit(bins, [i])\n",
    "        m1, m2 = np.sum(p1 * b1)/q1, np.sum(p2 * b2)/q2\n",
    "        v1, v2 = np.sum(((b1 - m1)**2)*p1)/q1, np.sum(((b2 - m2)**2)*p2)/q2\n",
    "\n",
    "        fn = v1 * q1 + v2 * q2\n",
    "        if fn < fn_min:\n",
    "            fn_min = fn\n",
    "            thresh = i\n",
    "\n",
    "    cutoff = bins[thresh]\n",
    "    return cutoff, fn_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cis_trans_status(row):\n",
    "    if row.cis_status_one == \"significant cis effect\":\n",
    "        if row.trans_status_one == \"significant trans effect\":\n",
    "            if \"higher in human\" in row.cis_status_det_one:\n",
    "                if \"higher in human\" in row.trans_status_det_one:\n",
    "                    return \"cis/trans directional\"\n",
    "                else:\n",
    "                    return \"cis/trans compensatory\"\n",
    "            else:\n",
    "                if \"higher in human\" in row.trans_status_det_one:\n",
    "                    return \"cis/trans compensatory\"\n",
    "                else:\n",
    "                    return \"cis/trans directional\"\n",
    "        else:\n",
    "            return \"cis effect only\"\n",
    "    else:\n",
    "        if row.trans_status_one == \"significant trans effect\":\n",
    "            return \"trans effect only\"\n",
    "        else:\n",
    "            return \"no cis or trans effects\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = \"../../../data/02__mpra/03__results/all_processed_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory w/ correlation info\n",
    "corr_dir = \"../../../misc/04__enh_tss_corrs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_nearby_elems_f = \"../../../misc/03__nearby_elems/hg19.all_TSS_and_enh_within_tad.txt\"\n",
    "mm9_nearby_elems_f = \"../../../misc/03__nearby_elems/mm9.all_TSS_and_enh_within_tad.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_tads_f = \"../../../misc/03__nearby_elems/hg19_evo.tad_assignments.txt\"\n",
    "mm9_tads_f = \"../../../misc/03__nearby_elems/mm9_evo.tad_assignments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(data_f)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...importing human files...\n",
      "...importing mouse files...\n"
     ]
    }
   ],
   "source": [
    "# import correlation files\n",
    "human_chroms = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \n",
    "                \"19\", \"20\", \"21\", \"22\", \"X\"]\n",
    "mouse_chroms = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \n",
    "                \"19\", \"X\"]\n",
    "\n",
    "human_corr_dict = {}\n",
    "mouse_corr_dict = {}\n",
    "\n",
    "for chroms, corr_dict, suffix, sp in zip([human_chroms, mouse_chroms], [human_corr_dict, mouse_corr_dict], \n",
    "                                         [\"hg19\", \"mm9\"], [\"human\", \"mouse\"]):\n",
    "    print(\"...importing %s files...\" % sp)\n",
    "    for chrom in chroms:\n",
    "        file = \"%s/%s/%s.chr%s.corr.txt\" % (corr_dir, sp, suffix, chrom)\n",
    "        try:\n",
    "            df = pd.read_table(file)\n",
    "            df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "            df.index.name = \"Id\"\n",
    "            corr_dict[chrom] = df\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_nearby_elems = pd.read_table(hg19_nearby_elems_f, header=None, names=[\"tss_chr\", \"tss_start\", \"tss_end\",\n",
    "                                                                           \"name\", \"score\", \"tss_strand\", \"elem_chr\",\n",
    "                                                                           \"elem_start\", \"elem_end\", \"elem_id\", \n",
    "                                                                           \"elem_score\", \"elem_strand\", \"overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm9_nearby_elems = pd.read_table(mm9_nearby_elems_f, header=None, names=[\"tss_chr\", \"tss_start\", \"tss_end\",\n",
    "                                                                         \"name\", \"score\", \"tss_strand\", \"elem_chr\",\n",
    "                                                                         \"elem_start\", \"elem_end\", \"elem_id\", \n",
    "                                                                         \"elem_score\", \"elem_strand\", \"overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_tads = pd.read_table(hg19_tads_f, sep=\"\\t\", header=None, names=[\"tss_chr\", \"tss_start\", \"tss_end\", \"name\",\n",
    "                                                                     \"score\", \"tss_strand\", \"tad_chr\", \"tad_start\",\n",
    "                                                                     \"tad_end\", \"len\", \"overlap\"])\n",
    "#hg19_tads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm9_tads = pd.read_table(mm9_tads_f, sep=\"\\t\", header=None, names=[\"tss_chr\", \"tss_start\", \"tss_end\", \"name\",\n",
    "                                                                     \"score\", \"tss_strand\", \"tad_chr\", \"tad_start\",\n",
    "                                                                     \"tad_end\", \"len\", \"overlap\"])\n",
    "#mm9_tads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. find number of highly correlated regulatory elements w/in the same TAD (defined by Bing Ren's group in hESCs and mESCs) for every element in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to define \"highly correlated\" regulatory elements, use Otsu's binarization threshold, which finds the optimal \"threshold\" in a histogram.\n",
    "\n",
    "steps:\n",
    "1. for all elements in MPRA, find all elements that are in the same TAD\n",
    "2. get a histogram of the correlations of these nearby elements w/ the element of interest in the MPRA\n",
    "3. use Otsu's binarization method to set a cut-off in the histogram between noise & not-noise\n",
    "4. count how many elements pass the not-noise cut-off\n",
    "5. require element to have at least 10 nearby elements to do this analysis (otherwise thresholding is unreliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_nearby_elems[\"hg19_id\"] = hg19_nearby_elems[\"name\"].str.split(\"__\", expand=True)[1]\n",
    "hg19_nearby_elems[\"tss_tile_num\"] = hg19_nearby_elems[\"name\"].str.split(\"__\", \n",
    "                                                                    expand=True)[2].str.split(\";\", expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm9_nearby_elems[\"mm9_id\"] = mm9_nearby_elems[\"name\"].str.split(\"__\", expand=True)[1]\n",
    "mm9_nearby_elems[\"tss_tile_num\"] = mm9_nearby_elems[\"name\"].str.split(\"__\", \n",
    "                                                                  expand=True)[2].str.split(\";\", expand=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg19_nearby_elems_filt = hg19_nearby_elems[[\"tss_chr\", \"hg19_id\", \"tss_tile_num\", \"elem_id\"]].drop_duplicates()\n",
    "len(hg19_nearby_elems_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761280"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge w/ MPRA data so we can map ID to cage ID\n",
    "hg19_nearby_elems_filt = hg19_nearby_elems_filt.merge(data[[\"hg19_id\", \"cage_id_hg19\"]], \n",
    "                                                      on=\"hg19_id\").drop_duplicates()\n",
    "len(hg19_nearby_elems_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm9_nearby_elems_filt = mm9_nearby_elems[[\"tss_chr\", \"mm9_id\", \"tss_tile_num\", \"elem_id\"]].drop_duplicates()\n",
    "len(mm9_nearby_elems_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815983"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge w/ MPRA data so we can map ID to cage ID\n",
    "mm9_nearby_elems_filt = mm9_nearby_elems_filt.merge(data[[\"mm9_id\", \"cage_id_mm9\"]], \n",
    "                                                      on=\"mm9_id\").drop_duplicates()\n",
    "len(mm9_nearby_elems_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY LOOK AT ELEMENTS THAT HAVE AT LEAST THE FOLLOWING # OF NEARBY ELEMENTS IN THE SAME TAD\n",
    "NEARBY_CUTOFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding otsu thresh for hg19...\n",
      "...finding otsu thresh for mm9...\n"
     ]
    }
   ],
   "source": [
    "human_chroms = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \n",
    "                \"19\", \"20\", \"21\", \"22\", \"X\"]\n",
    "mouse_chroms = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \n",
    "                \"19\", \"X\"]\n",
    "\n",
    "hg19_otsu = {}\n",
    "mm9_otsu = {}\n",
    "\n",
    "for chroms, otsu, corr_dict, nearby_elems_filt, suffix in zip([human_chroms, mouse_chroms], [hg19_otsu, mm9_otsu],\n",
    "                                                              [human_corr_dict, mouse_corr_dict], \n",
    "                                                              [hg19_nearby_elems_filt, mm9_nearby_elems_filt],\n",
    "                                                              [\"hg19\", \"mm9\"]):\n",
    "    print(\"...finding otsu thresh for %s...\" % suffix)\n",
    "    for chrom in chroms:\n",
    "        corr_df = np.abs(corr_dict[chrom]).reset_index()\n",
    "        mpra_ids = list(corr_df[\"Id\"])\n",
    "        if len(corr_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        # find the elements w/in the same TAD as each element in MPRA\n",
    "        for mpra_id in mpra_ids:\n",
    "            nearby_ids = list(nearby_elems_filt[nearby_elems_filt[\"cage_id_%s\" % suffix] == mpra_id][\"elem_id\"])\n",
    "            nearby_ids = list(set(nearby_ids))\n",
    "            nearby_ids = [x for x in nearby_ids if x != mpra_id]\n",
    "            nearby_tss = [x for x in nearby_ids if \",\" in x]\n",
    "            nearby_enh = [x for x in nearby_ids if \",\" not in x]\n",
    "            \n",
    "            # limit corr df to IDs of interest\n",
    "            mpra_id_dict = {}\n",
    "            for ids, elem_type in zip([nearby_ids, nearby_tss, nearby_enh], [\"both\", \"tss\", \"enh\"]):\n",
    "                sub_corr_df = corr_df[corr_df[\"Id\"] == mpra_id][ids]\n",
    "                vals = list(sub_corr_df.iloc[0])\n",
    "                \n",
    "                # calculate otsu threshold if there are enough nearby elements\n",
    "                if len(vals) >= NEARBY_CUTOFF:\n",
    "                    otsu_thresh, fn_min = modified_otsu(vals, 100, 0, 1)\n",
    "                    n_ov_otsu = len([x for x in vals if x >= otsu_thresh])\n",
    "                else:\n",
    "                    otsu_thresh, fn_min, n_ov_otsu = np.nan, np.nan, np.nan\n",
    "                \n",
    "                mpra_id_dict[\"n_nearby_%s\" % elem_type] = len(vals)\n",
    "                mpra_id_dict[\"otsu_%s\" % elem_type] = otsu_thresh\n",
    "                mpra_id_dict[\"n_ov_otsu_%s\" % elem_type] = n_ov_otsu\n",
    "        \n",
    "            otsu[mpra_id] = mpra_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_otsu_df = pd.DataFrame.from_dict(hg19_otsu, orient=\"index\").reset_index()\n",
    "hg19_otsu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm9_otsu_df = pd.DataFrame.from_dict(mm9_otsu, orient=\"index\").reset_index()\n",
    "mm9_otsu_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. plot some examples of what Otsu binarization actually looks like\n",
    "\n",
    "do human only for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_chroms = [\"8\"]\n",
    "ids = [\"chr8:128807259..128807281,+\"]\n",
    "c = 1\n",
    "\n",
    "for chrom, idx in zip(ex_chroms, ids):\n",
    "    corr_df = np.abs(human_corr_dict[chrom]).reset_index()\n",
    "    nearby_ids = set(list(hg19_nearby_elems_filt[hg19_nearby_elems_filt[\"cage_id_hg19\"] == idx][\"elem_id\"]))\n",
    "    nearby_ids = [x for x in nearby_ids if x != idx]\n",
    "    nearby_enh = [x for x in nearby_ids if \",\" not in x]\n",
    "    print(\"total enhancers w/in the same TAD: %s\" % len(nearby_enh))\n",
    "    sub_corr_df = corr_df[corr_df[\"Id\"] == idx][nearby_enh]\n",
    "    vals = list(sub_corr_df.iloc[0])\n",
    "    otsu, fn_min = modified_otsu(vals, 100, 0, 1)\n",
    "    n_ov = len([x for x in vals if x >= otsu])\n",
    "    n_un = len([x for x in vals if x < otsu])\n",
    "    \n",
    "    # plt\n",
    "    fig = plt.figure(figsize=(2, 1.25))\n",
    "    ax = sns.distplot(vals, color=sns.color_palette(\"Set2\")[1], kde=True, bins=15)\n",
    "    if n_ov == 1:\n",
    "        text = \"1\\eRNA\"\n",
    "    else:\n",
    "        text = \"%s\\neRNAs\" % n_ov\n",
    "    ax.annotate(text, xy=(0.97, 0.95), xycoords=\"axes fraction\", xytext=(0, 0), \n",
    "                textcoords=\"offset pixels\", ha='right', va='top', \n",
    "                size=fontsize)\n",
    "    \n",
    "    ax.axvline(x=otsu, linestyle=\"dashed\", color=\"black\")\n",
    "    ax.set_xlabel(\"correlation with eRNAs\\nwithin the same TAD\")\n",
    "    ax.set_ylabel(\"density\")\n",
    "    ax.set_title(idx)\n",
    "    plt.show()\n",
    "    fig.savefig(\"Fig6H.pdf\", dpi=\"figure\", bbox_inches=\"tight\")\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. assign cis/trans status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cis_trans_status\"] = data.apply(cis_trans_status, axis=1)\n",
    "data.cis_trans_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~pd.isnull(data[\"minimal_biotype_hg19\"])]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt = data[((data[\"HUES64_padj_hg19\"] < QUANT_ALPHA) | (data[\"mESC_padj_mm9\"] < QUANT_ALPHA))]\n",
    "len(data_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_sp = data_filt.drop(\"orig_species\", axis=1)\n",
    "data_filt_sp.drop_duplicates(inplace=True)\n",
    "len(data_filt_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. merge cis/trans status with redundant enhancer info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_sp = data_filt_sp.merge(hg19_otsu_df, left_on=\"cage_id_hg19\", right_on=\"index\", how=\"left\")\n",
    "data_filt_sp = data_filt_sp.merge(mm9_otsu_df, left_on=\"cage_id_mm9\", right_on=\"index\", how=\"left\",\n",
    "                                  suffixes=(\"_hg19\", \"_mm9\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_sp[\"mean_n_nearby_enh\"] = data_filt_sp[[\"n_nearby_enh_hg19\", \"n_nearby_enh_mm9\"]].mean(axis=1)\n",
    "data_filt_sp[\"mean_n_ov_otsu_enh\"] = data_filt_sp[[\"n_ov_otsu_enh_hg19\", \"n_ov_otsu_enh_mm9\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_sp.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. how many elements within the same TAD, broken up by cis/trans status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\"no cis or trans effects\", \"cis/trans compensatory\", \"cis effect only\", \"trans effect only\",\n",
    "         \"cis/trans directional\"]\n",
    "min_order = [\"cis/trans compensatory\", \"cis/trans directional\"]\n",
    "pal = {\"no cis or trans effects\": sns.color_palette(\"Set2\")[7], \"cis effect only\": sns.color_palette(\"Set2\")[2],\n",
    "       \"trans effect only\": sns.color_palette(\"Set2\")[2], \"cis/trans directional\": sns.color_palette(\"Set2\")[2],\n",
    "       \"cis/trans compensatory\": sns.color_palette(\"Set2\")[7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_filt_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"mean_n_nearby_enh\"]\n",
    "ylabels = [ \"# of eRNAs\\nwithin the same TAD\"]\n",
    "ylims = [(-30, 150)]\n",
    "yps = [55]\n",
    "plots = [\"enh\"]\n",
    "\n",
    "for col, ylabel, ylim, yp, plot in zip(cols, ylabels, ylims, yps, plots):\n",
    "    fig = plt.figure(figsize=(1, 1.5))\n",
    "    \n",
    "    ax = sns.boxplot(data=df, x=\"cis_trans_status\", y=col, order=min_order, \n",
    "                 flierprops = dict(marker='o', markersize=5), palette=pal)\n",
    "    mimic_r_boxplot(ax)\n",
    "\n",
    "    ax.set_xticklabels([\"compensatory\", \"directional\"], rotation=50, ha='right', va='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    for i, l in enumerate(min_order):\n",
    "        sub = df[df[\"cis_trans_status\"] == l]\n",
    "        n = len(sub)\n",
    "        print(\"%s median: %s\" % (l, sub[col].median()))\n",
    "        color = pal[l]\n",
    "        ax.annotate(str(n), xy=(i, ylim[0]+3), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=color, size=fontsize)\n",
    "\n",
    "    ### pvals ###\n",
    "    vals1 = np.asarray(df[df[\"cis_trans_status\"] == \"cis/trans compensatory\"][col])\n",
    "    vals2 = np.asarray(df[df[\"cis_trans_status\"] == \"cis/trans directional\"][col])\n",
    "\n",
    "    vals1 = vals1[~np.isnan(vals1)]\n",
    "    vals2 = vals2[~np.isnan(vals2)]\n",
    "\n",
    "    _, pval12 = stats.mannwhitneyu(vals1, vals2, alternative=\"two-sided\", use_continuity=False)\n",
    "\n",
    "    annotate_pval(ax, 0.2, 0.8, yp, 0, yp, pval12, fontsize-1)\n",
    "\n",
    "    ax.set_ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. how many elements w/in the same TAD, broken up by cis/trans status *and* conservation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cage_status(row):\n",
    "    if \"CAGE turnover\" in row.biotype_switch_minimal:\n",
    "        return \"turnover\"\n",
    "    else:\n",
    "        return \"conserved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cage_status\"] = df.apply(cage_status, axis=1)\n",
    "df[\"tmp\"] = df[\"cage_status\"] + \"__\" + df[\"cis_trans_status\"]\n",
    "df.tmp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_cons = [\"turnover__cis/trans compensatory\", \"turnover__cis/trans directional\",\n",
    "              \"conserved__cis/trans compensatory\", \"conserved__cis/trans directional\"]\n",
    "xlabels_cons = [\"compensatory\", \"directional\", \"compensatory\", \"directional\"]\n",
    "pal_cons = {\"turnover__cis/trans compensatory\": sns.color_palette(\"Set2\")[7],\n",
    "            \"turnover__cis/trans directional\": sns.color_palette(\"Set2\")[2],\n",
    "            \"conserved__cis/trans compensatory\": sns.color_palette(\"Set2\")[7],\n",
    "            \"conserved__cis/trans directional\": sns.color_palette(\"Set2\")[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims_sep = [(-17, 100)]\n",
    "yps_sep_a = [55]\n",
    "yps_sep_b = [55]\n",
    "\n",
    "for col, ylabel, ylim, yp_a, yp_b, plot in zip(cols, ylabels, ylims_sep, yps_sep_a, yps_sep_b, plots):\n",
    "\n",
    "    fig = plt.figure(figsize=(2.2, 1.5))\n",
    "    ax = sns.boxplot(data=df, x=\"tmp\", y=col, order=order_cons, \n",
    "                     flierprops = dict(marker='o', markersize=5), palette=pal_cons)\n",
    "    mimic_r_boxplot(ax)\n",
    "\n",
    "    ax.set_xticklabels(xlabels_cons, rotation=50, ha='right', va='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.axvline(x=1.5, linestyle=\"dashed\", linewidth=1, color=\"black\")\n",
    "\n",
    "    for i, l in enumerate(order_cons):\n",
    "        sub = df[df[\"tmp\"] == l]\n",
    "        n = len(sub)\n",
    "        print(\"%s median: %s\" % (l, sub[col].median()))\n",
    "        color = pal_cons[l]\n",
    "        ax.annotate(str(n), xy=(i, ylim[0]+3), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=color, size=fontsize)\n",
    "\n",
    "    ### pvals ###\n",
    "    vals1 = np.asarray(df[df[\"tmp\"] == \"turnover__cis/trans compensatory\"][col])\n",
    "    vals2 = np.asarray(df[df[\"tmp\"] == \"turnover__cis/trans directional\"][col])\n",
    "    vals3 = np.asarray(df[df[\"tmp\"] == \"conserved__cis/trans compensatory\"][col])\n",
    "    vals4 = np.asarray(df[df[\"tmp\"] == \"conserved__cis/trans directional\"][col])\n",
    "\n",
    "    vals1 = vals1[~np.isnan(vals1)]\n",
    "    vals2 = vals2[~np.isnan(vals2)]\n",
    "    vals3 = vals3[~np.isnan(vals3)]\n",
    "    vals4 = vals4[~np.isnan(vals4)]\n",
    "\n",
    "    _, pval12 = stats.mannwhitneyu(vals1, vals2, alternative=\"two-sided\", use_continuity=False)\n",
    "    _, pval34 = stats.mannwhitneyu(vals3, vals4, alternative=\"two-sided\", use_continuity=False)\n",
    "\n",
    "    annotate_pval(ax, 0.2, 0.8, yp_a, 0, yp_a, pval12, fontsize-1)\n",
    "    annotate_pval(ax, 2.2, 2.8, yp_b, 0, yp_b, pval34, fontsize-1)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(\"Fig6G.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. how many redundant elements, broken up by cis/trans status?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how many \"highly\" correlated regulatory elements (both enhancers + TSSs), TSSs only, and enhancers only are there within the same TAD on average for elements that show either compensatory or directional cis/trans effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"mean_n_ov_otsu_enh\"]\n",
    "ylabels = [\"# of correlated eRNAs\\nwithin the same TAD\"]\n",
    "ylims = [(-30, 200), (-30, 200), (-10, 50)]\n",
    "yps = [55, 50, 18]\n",
    "plots = [\"both\", \"TSS\", \"enh\"]\n",
    "\n",
    "for col, ylabel, ylim, yp, plot in zip(cols, ylabels, ylims, yps, plots):\n",
    "    fig = plt.figure(figsize=(1, 1.5))\n",
    "    \n",
    "    ax = sns.boxplot(data=df, x=\"cis_trans_status\", y=col, order=min_order, \n",
    "                 flierprops = dict(marker='o', markersize=5), palette=pal)\n",
    "    mimic_r_boxplot(ax)\n",
    "\n",
    "    ax.set_xticklabels([\"compensatory\", \"directional\"], rotation=50, ha='right', va='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    for i, l in enumerate(min_order):\n",
    "        sub = df[df[\"cis_trans_status\"] == l]\n",
    "        n = len(sub)\n",
    "        print(\"%s median: %s\" % (l, sub[col].median()))\n",
    "        color = pal[l]\n",
    "        ax.annotate(str(n), xy=(i, ylim[0]+3), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=color, size=fontsize)\n",
    "\n",
    "    ### pvals ###\n",
    "    vals1 = np.asarray(df[df[\"cis_trans_status\"] == \"cis/trans compensatory\"][col])\n",
    "    vals2 = np.asarray(df[df[\"cis_trans_status\"] == \"cis/trans directional\"][col])\n",
    "\n",
    "    vals1 = vals1[~np.isnan(vals1)]\n",
    "    vals2 = vals2[~np.isnan(vals2)]\n",
    "\n",
    "    _, pval12 = stats.mannwhitneyu(vals1, vals2, alternative=\"two-sided\", use_continuity=False)\n",
    "\n",
    "    annotate_pval(ax, 0.2, 0.8, yp, 0, yp, pval12, fontsize-1)\n",
    "\n",
    "    ax.set_ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trend's there but weak; what happens if we subset by conservation pattern and ask the same question? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims_sep = [(-5, 40)]\n",
    "yps_sep_a = [25]\n",
    "yps_sep_b = [23]\n",
    "\n",
    "for col, ylabel, ylim, yp_a, yp_b, plot in zip(cols, ylabels, ylims_sep, yps_sep_a, yps_sep_b, plots):\n",
    "\n",
    "    fig = plt.figure(figsize=(2.2, 1.5))\n",
    "    ax = sns.boxplot(data=df, x=\"tmp\", y=col, order=order_cons, \n",
    "                     flierprops = dict(marker='o', markersize=5), palette=pal_cons)\n",
    "    mimic_r_boxplot(ax)\n",
    "\n",
    "    ax.set_xticklabels(xlabels_cons, rotation=50, ha='right', va='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.axvline(x=1.5, linestyle=\"dashed\", linewidth=1, color=\"black\")\n",
    "\n",
    "    for i, l in enumerate(order_cons):\n",
    "        sub = df[df[\"tmp\"] == l]\n",
    "        n = len(sub)\n",
    "        print(\"%s median: %s\" % (l, sub[col].median()))\n",
    "        color = pal_cons[l]\n",
    "        if \"enh\" in col:\n",
    "            y = ylim[0] + 0.5\n",
    "        else:\n",
    "            y = ylim[0] + 3\n",
    "        ax.annotate(str(n), xy=(i, y), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=color, size=fontsize)\n",
    "\n",
    "    ### pvals ###\n",
    "    vals1 = np.asarray(df[df[\"tmp\"] == \"turnover__cis/trans compensatory\"][col])\n",
    "    vals2 = np.asarray(df[df[\"tmp\"] == \"turnover__cis/trans directional\"][col])\n",
    "    vals3 = np.asarray(df[df[\"tmp\"] == \"conserved__cis/trans compensatory\"][col])\n",
    "    vals4 = np.asarray(df[df[\"tmp\"] == \"conserved__cis/trans directional\"][col])\n",
    "\n",
    "    vals1 = vals1[~np.isnan(vals1)]\n",
    "    vals2 = vals2[~np.isnan(vals2)]\n",
    "    vals3 = vals3[~np.isnan(vals3)]\n",
    "    vals4 = vals4[~np.isnan(vals4)]\n",
    "\n",
    "    _, pval12 = stats.mannwhitneyu(vals1, vals2, alternative=\"two-sided\", use_continuity=False)\n",
    "    _, pval34 = stats.mannwhitneyu(vals3, vals4, alternative=\"two-sided\", use_continuity=False)\n",
    "\n",
    "    annotate_pval(ax, 0.2, 0.8, yp_a, 0, yp_a, pval12, fontsize-1)\n",
    "    annotate_pval(ax, 2.2, 2.8, yp_b, 0, yp_b, pval34, fontsize-1)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(\"Fig6I.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cool! as expected, the trend we see is limited to *conserved* regulatory elements (i.e., those that have CAGE peak in both human and mouse). if there is a directional trend at a conserved element, it is associated w/ higher numbers of redundant elements within the same TAD. this is not true at non-conserved elements, which in general are just noisy and likely acquire directional effects but there is no strong selection to stabilize their activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_biotype(row):\n",
    "    if row.minimal_biotype_hg19 == \"no CAGE activity\":\n",
    "        return row.minimal_biotype_mm9\n",
    "    elif row.biotype_switch_minimal == \"biotype switch\":\n",
    "        return \"biotype switch\"\n",
    "    else:\n",
    "        return row.minimal_biotype_hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"one_biotype\"] = df.apply(one_biotype, axis=1)\n",
    "df.one_biotype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cons = df[df[\"cage_status\"] == \"conserved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims = [(-5, 40)]\n",
    "yps = [30]\n",
    "for col, ylabel, ylim, yp, plot in zip(cols, ylabels, ylims_sep, yps, plots):\n",
    "\n",
    "    fig = plt.figure(figsize=(2.2, 1.5))\n",
    "    ax = sns.boxplot(data=df_cons, x=\"one_biotype\", y=col, order=[\"eRNA\", \"lncRNA\", \"mRNA\"], hue=\"cis_trans_status\",\n",
    "                     hue_order=[\"cis/trans compensatory\", \"cis/trans directional\"],\n",
    "                     flierprops = dict(marker='o', markersize=5), palette=pal)\n",
    "    mimic_r_boxplot(ax)\n",
    "\n",
    "    ax.set_xticklabels([\"eRNA\", \"lncRNA\", \"mRNA\"], rotation=50, ha='right', va='top')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(ylim)\n",
    "    #ax.axvline(x=1.5, linestyle=\"dashed\", linewidth=1, color=\"black\")\n",
    "\n",
    "    for i, l in enumerate([\"eRNA\", \"lncRNA\", \"mRNA\"]):\n",
    "        sub = df_cons[df_cons[\"one_biotype\"] == l]\n",
    "        sub1 = sub[sub[\"cis_trans_status\"] == \"cis/trans compensatory\"]\n",
    "        sub2 = sub[sub[\"cis_trans_status\"] == \"cis/trans directional\"]\n",
    "        n1 = len(sub1)\n",
    "        n2 = len(sub2)\n",
    "        if \"enh\" in col:\n",
    "            y = ylim[0] + 0.5\n",
    "        else:\n",
    "            y = ylim[0] + 3\n",
    "        ax.annotate(str(n1), xy=(i-0.25, y), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=sns.color_palette(\"Set2\")[7], size=fontsize)\n",
    "        ax.annotate(str(n2), xy=(i+0.25, y), xycoords=\"data\", xytext=(0, 0), \n",
    "                    textcoords=\"offset pixels\", ha='center', va='bottom', \n",
    "                    color=sns.color_palette(\"Set2\")[2], size=fontsize)\n",
    "        \n",
    "        ## pvals ##\n",
    "        vals1 = np.asarray(sub1[col])\n",
    "        vals2 = np.asarray(sub2[col])\n",
    "        vals1 = vals1[~np.isnan(vals1)]\n",
    "        vals2 = vals2[~np.isnan(vals2)]\n",
    "        _, pval12 = stats.mannwhitneyu(vals1, vals2, alternative=\"two-sided\", use_continuity=False)\n",
    "        annotate_pval(ax, i-0.2, i+0.2, yp, 0, yp, pval12, fontsize-1)\n",
    "    \n",
    "    plt.legend(loc=2, bbox_to_anchor=(1.1, 1))\n",
    "    plt.show()\n",
    "    fig.savefig(\"FigS14.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. sub-sample within the same TAD\n",
    "\n",
    "since we have several examples of regulatory elements in the MPRA that are w/in close proximity, which could really bias this analysis, let's try and control for that. so what I did for that is to sub-sample regulatory elements based on their TAD assignment in human & mouse: only sample 1 element from each TAD and then plot. I made 10 plots after sub-sampling, and while it's much noisier (we lose precious data), the trend is still there, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19_tads[\"hg19_id\"] = hg19_tads[\"name\"].str.split(\"__\", expand=True)[1]\n",
    "hg19_tads[\"tad_id\"] = hg19_tads[\"tad_chr\"] + \":\" + hg19_tads[\"tad_start\"].astype(str)\n",
    "#hg19_tads.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm9_tads[\"mm9_id\"] = mm9_tads[\"name\"].str.split(\"__\", expand=True)[1]\n",
    "mm9_tads[\"tad_id\"] = mm9_tads[\"tad_chr\"] + \":\" + mm9_tads[\"tad_start\"].astype(str)\n",
    "#mm9_tads.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_tad = data_filt_sp.merge(hg19_tads[[\"hg19_id\", \"tad_id\"]], on=\"hg19_id\", how=\"left\")\n",
    "data_filt_tad = data_filt_tad.merge(mm9_tads[[\"mm9_id\", \"tad_id\"]], on=\"mm9_id\", suffixes=(\"_hg19\", \"_mm9\"), \n",
    "                                    how=\"left\")\n",
    "data_filt_tad.drop_duplicates(inplace=True)\n",
    "#len(data_filt_tad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filt_tad[\"tad_id_both\"] = data_filt_tad[\"tad_id_hg19\"].astype(str) + \"__\" + data_filt_tad[\"tad_id_mm9\"].astype(str)\n",
    "#data_filt_tad.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"mean_n_ov_otsu_enh\"\n",
    "ylabel = \"# of correlated enhancers\\nwithin the same TAD\"\n",
    "ylim = (-8, 40)\n",
    "yp_a = 15\n",
    "yp_b = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sampling from unique TAD IDs 1000 times\")\n",
    "\n",
    "samp_results = {}\n",
    "for x in range(1000):\n",
    "    data_shuf = data_filt_tad.sample(frac=1)\n",
    "    data_shuf_sub = data_shuf[[\"biotype_switch_minimal\", \"cis_trans_status\", \"tad_id_both\", \"mean_n_ov_otsu_enh\"]]\n",
    "    data_shuf_sub = data_shuf_sub[~pd.isnull(data_shuf_sub[\"mean_n_ov_otsu_enh\"])]\n",
    "    data_shuf_sub = data_shuf_sub.drop_duplicates(subset=[\"tad_id_both\"])\n",
    "    \n",
    "    # calculate median of conserved comp/direc and non-conserved comp/direc\n",
    "    data_non_cons = data_shuf_sub[data_shuf_sub[\"biotype_switch_minimal\"].str.contains(\"CAGE turnover\")]\n",
    "    data_cons = data_shuf_sub[data_shuf_sub[\"biotype_switch_minimal\"].isin([\"eRNA\", \"lncRNA\", \"mRNA\"])]\n",
    "    data_non_cons_comp = data_non_cons[data_non_cons[\"cis_trans_status\"] == \"cis/trans compensatory\"]\n",
    "    data_non_cons_direc = data_non_cons[data_non_cons[\"cis_trans_status\"] == \"cis/trans directional\"]\n",
    "    data_cons_comp = data_cons[data_cons[\"cis_trans_status\"] == \"cis/trans compensatory\"]\n",
    "    data_cons_direc = data_cons[data_cons[\"cis_trans_status\"] == \"cis/trans directional\"]\n",
    "    \n",
    "    # first enhancers\n",
    "    vals_non_cons_comp = np.asarray(data_non_cons_comp[\"mean_n_ov_otsu_enh\"])\n",
    "    vals_non_cons_direc = np.asarray(data_non_cons_direc[\"mean_n_ov_otsu_enh\"])\n",
    "    vals_cons_comp = np.asarray(data_cons_comp[\"mean_n_ov_otsu_enh\"])\n",
    "    vals_cons_direc = np.asarray(data_cons_direc[\"mean_n_ov_otsu_enh\"])\n",
    "    \n",
    "    \n",
    "    med_non_cons_comp = np.median(vals_non_cons_comp)\n",
    "    med_non_cons_direc = np.median(vals_non_cons_direc)\n",
    "    med_cons_comp = np.median(vals_cons_comp)\n",
    "    med_cons_direc = np.median(vals_cons_direc)\n",
    "    med_non_cons_diff = med_non_cons_direc - med_non_cons_comp\n",
    "    med_cons_diff = med_cons_direc - med_cons_comp\n",
    "    \n",
    "    \n",
    "    samp_results[x] = {\"med_non_cons_comp\": med_non_cons_comp,\n",
    "                       \"med_non_cons_direc\": med_non_cons_direc, \"med_cons_comp\": med_cons_comp, \n",
    "                       \"med_cons_direc\": med_cons_direc, \"med_non_cons_diff\": med_non_cons_diff, \n",
    "                       \"med_cons_diff\": med_cons_diff}\n",
    "\n",
    "samp_results = pd.DataFrame.from_dict(samp_results, orient=\"index\")\n",
    "samp_results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the 95% confidence interval for every statistic\n",
    "print(\"====== ENHANCERS ======\")\n",
    "samp_results = samp_results.sort_values(by=\"med_non_cons_comp\")\n",
    "med_non_cons_comp_lb = samp_results[\"med_non_cons_comp\"].iloc[25]\n",
    "med_non_cons_comp_ub = samp_results[\"med_non_cons_comp\"].iloc[975]\n",
    "print(\"non-conserved compensatory 95%% confidence interval: %s - %s\" % (med_non_cons_comp_lb, med_non_cons_comp_ub))\n",
    "\n",
    "samp_results = samp_results.sort_values(by=\"med_non_cons_direc\")\n",
    "med_non_cons_direc_lb = samp_results[\"med_non_cons_direc\"].iloc[25]\n",
    "med_non_cons_direc_ub = samp_results[\"med_non_cons_direc\"].iloc[975]\n",
    "print(\"non-conserved directional 95%% confidence interval: %s - %s\" % (med_non_cons_direc_lb, med_non_cons_direc_ub))\n",
    "\n",
    "samp_results = samp_results.sort_values(by=\"med_cons_comp\")\n",
    "med_cons_comp_lb = samp_results[\"med_cons_comp\"].iloc[25]\n",
    "med_cons_comp_ub = samp_results[\"med_cons_comp\"].iloc[975]\n",
    "print(\"conserved compensatory 95%% confidence interval: %s - %s\" % (med_cons_comp_lb, med_cons_comp_ub))\n",
    "\n",
    "samp_results = samp_results.sort_values(by=\"med_cons_direc\")\n",
    "med_cons_direc_lb = samp_results[\"med_cons_direc\"].iloc[25]\n",
    "med_cons_direc_ub = samp_results[\"med_cons_direc\"].iloc[975]\n",
    "print(\"conserved directional 95%% confidence interval: %s - %s\" % (med_cons_direc_lb, med_cons_direc_ub))\n",
    "\n",
    "print(\"=======\")\n",
    "print(\"\")\n",
    "\n",
    "samp_results = samp_results.sort_values(by=\"med_non_cons_diff\")\n",
    "med_non_cons_diff_lb = samp_results[\"med_non_cons_diff\"].iloc[25]\n",
    "med_non_cons_diff_ub = samp_results[\"med_non_cons_diff\"].iloc[975]\n",
    "print(\"non-conserved median difference 95%% confidence interval: %s - %s\" % (med_non_cons_diff_lb, med_non_cons_diff_ub))\n",
    "\n",
    "samp_results = samp_results.sort_values(by=\"med_cons_diff\")\n",
    "med_cons_diff_lb = samp_results[\"med_cons_diff\"].iloc[25]\n",
    "med_cons_diff_ub = samp_results[\"med_cons_diff\"].iloc[975]\n",
    "print(\"conserved median difference 95%% confidence interval: %s - %s\" % (med_cons_diff_lb, med_cons_diff_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2, 1.25))\n",
    "ax = sns.distplot(samp_results[\"med_non_cons_diff\"], hist=False, color=sns.color_palette(\"Set2\")[2])\n",
    "ax.axvline(x=med_non_cons_diff_lb, linestyle=\"dotted\", color=sns.color_palette(\"Set2\")[2])\n",
    "ax.axvline(x=med_non_cons_diff_ub, linestyle=\"dotted\", color=sns.color_palette(\"Set2\")[2])\n",
    "ax.axvline(x=0, linestyle=\"dashed\", color=\"black\")\n",
    "ax.set_ylabel(\"density\")\n",
    "ax.set_xlabel(\"difference in median # redundant eRNAs\\n(directional - compensatory)\")\n",
    "ax.set_title(\"non-conserved elements\")\n",
    "ax.set_xlim((-10, 10))\n",
    "fig.savefig(\"FigS15A.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2, 1.25))\n",
    "ax = sns.distplot(samp_results[\"med_cons_diff\"], hist=False, color=sns.color_palette(\"Set2\")[7])\n",
    "ax.axvline(x=med_cons_diff_lb, linestyle=\"dotted\", color=sns.color_palette(\"Set2\")[7])\n",
    "ax.axvline(x=med_cons_diff_ub, linestyle=\"dotted\", color=sns.color_palette(\"Set2\")[7])\n",
    "ax.axvline(x=0, linestyle=\"dashed\", color=\"black\")\n",
    "ax.set_ylabel(\"density\")\n",
    "ax.set_xlabel(\"difference in median # redundant eRNAs\\n(directional - compensatory)\")\n",
    "ax.set_title(\"conserved elements\")\n",
    "ax.set_xlim((-10, 10))\n",
    "fig.savefig(\"FigS15B.pdf\", dpi=\"figure\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 95% confidence interval of differences b/w # of correlated enhancers trends negative (-6 to 0) meaning that non-conserved elements have higher correlated enhancers for compensatory ones; the 95% confidence interval trends positive (0 to 6.5) for conserved elements, which fits w/ earlier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py36]",
   "language": "python",
   "name": "conda-env-.conda-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
